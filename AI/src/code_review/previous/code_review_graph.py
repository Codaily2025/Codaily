from .schema import FeatureInferenceRequest, ChecklistEvaluationRequest, CodeReviewState, FeatureReviewSummaryRequest, FeatureChecklistRequest, FeatureChecklistResponse, CodeReviewItemRequest
from .code_review_prompts import feature_inference_prompt, checklist_evaluation_prompt, code_review_prompt, review_summary_prompt
from .feature_checklist_prompt import feature_checklist_prompt
from typing import Dict
from langchain_community.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, END

import os
import httpx
import json
import asyncpg
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
POSTGRES_URI = os.getenv("POSTGRES_URI")

JAVA_API_URL = "http://localhost:8080/api"  # í¬íŠ¸ ë²ˆí˜¸ì™€ context pathëŠ” ë„ˆ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •


llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)


async def run_feature_inference(state: CodeReviewState) -> CodeReviewState:
    diff_files = state["diff_files"]
    available_features = state["available_features"]

    # diff ì •ë¦¬
    diff_text = ""
    for file in diff_files:
        diff_text += f"\nğŸ“„ {file['file_path']}:\n{file['patch']}\n"

    formatted_features = ", ".join(available_features)

    # GPT í˜¸ì¶œ
    response = await feature_inference_prompt.invoke({
        "diff_text": diff_text,
        "available_features": formatted_features
    })

    raw_result = response.content.strip()
    print("ğŸ§  ê¸°ëŠ¥ ì¶”ë¡  ê²°ê³¼:", raw_result)

    # ê¸°ëŠ¥ íŒŒì‹±
    if "ê¸°ëŠ¥ ì—†ìŒ" in raw_result:
        feature_names = []
    else:
        feature_names = [fn.strip() for fn in raw_result.split(",") if fn.strip()]

    # stateì— ì €ì¥
    state["feature_names"] = feature_names
    return state


async def run_feature_implementation_check_test(state: Dict) -> Dict:
    # 1) stateì—ì„œ ê¸°ì¡´ ê°’ ì¶”ì¶œ
    feature_name = state.get("feature_name")
    checklist_items = state.get("checklist", [])  # List of item strings
    full_files = state.get("fullFiles", [])        # List of dicts with 'file_path' & 'content'

    # 2) ì „ì²´ ì½”ë“œ í•©ì¹˜ê¸°
    merged_code = "\n".join([
        f"# {f['file_path']}\n{f.get('content','')}" for f in full_files
    ])

    # 3) í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = checklist_evaluation_prompt.format_messages(
        featureName=feature_name,
        code=merged_code,
        checklist="\n".join([f"- {item}" for item in checklist_items])
    )

    # 4) LLM í˜¸ì¶œ ë° JSON íŒŒì‹±
    response = await llm.ainvoke(prompt)
    parsed = json.loads(response.content)

    # 5) state ì—…ë°ì´íŠ¸
    state["featureId"] = state.get("featureId")
    state["commitHash"] = state.get("commitHash")
    state["featureName"] = parsed.get("feature_name")
    state["implementsFeature"] = parsed.get("implements")
    state["checklistEvaluation"] = parsed.get("checklist_evaluation")
    state["extraImplemented"] = parsed.get("extra_implemented")
    state["checklistFileMap"] = parsed.get("checklist_file_map")

    # 6) ê²°ê³¼ state ë°˜í™˜
    return state


# ê¸°ëŠ¥ëª… ì¶”ë¡ 
# async def run_feature_inference(request: FeatureInferenceRequest) -> Dict:

#     # diff ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
#     diff_text = "\n".join(
#         [f"# {f.filePath}\n{f.diff}" for f in request.diffFiles]
#     )

#     # ê¸°ëŠ¥ ëª©ë¡ë„ ë¬¸ìì—´ë¡œ
#     feature_list = "\n".join([f"- {f}" for f in request.availableFeatures])

#     prompt = feature_inference_prompt.format_messages(
#         diff_text=diff_text,
#         available_features=feature_list
#     )

#     response = await llm.ainvoke(prompt)
#     content = response.content.strip()

#     return {
#         "project_id": request.projectId,
#         "user_id": request.userId,
#         "commit_id": request.commitId,
#         "commit_hash": request.commitHash,
#         "feature_name": content  # ì˜ˆ: "JWT ë°œê¸‰ ê¸°ëŠ¥" ë˜ëŠ” "ê¸°ëŠ¥ ì—†ìŒ"
#     }

# ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ êµ¬í˜„ í™•ì¸ ë° ì¶”ê°€ êµ¬í˜„ í•­ëª© í™•ì¸
# êµ¬í˜„ ì™„ë£Œëœ ì²´í¬ë¦¬ìŠ¤íŠ¸ì˜ íŒŒì¼ê²½ë¡œ ì €ì¥ (ì½”ë“œë¦¬ë·°ì—ì„œ í™œìš©)
async def run_feature_implementation_check(request: ChecklistEvaluationRequest) -> Dict:
    featureName = request.featureName
    checklist = request.checklistEvaluation
    files = request.fullFiles

    # ì „ì²´ ì½”ë“œ í•©ì¹˜ê¸°
    merged_code = "\n".join([f"# {f.filePath}\n{f.content}" for f in files])

    # checklist í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°
    prompt = checklist_evaluation_prompt.format_messages(
        featureName=featureName,
        code=merged_code,
        checklist="\n".join([f"- {item}" for item in checklist])
    )

    response = await llm.ainvoke(prompt)
    parsed = json.loads(response.content)
    
    return {
        "featureId": request.featureId,
        "commitHash": request.commitHash,
        "featureName": parsed["feature_name"],
        "implementsFeature": parsed["implements"],
        "checklistEvaluation": parsed["checklist_evaluation"],
        "extraImplemented": parsed["extra_implemented"],
        "checklistFileMap": parsed["checklist_file_map"]
    }

# ì²´í¬ë¦¬ìŠ¤íŠ¸ Trueì¸ í•­ëª©ë§Œ ì½”ë“œë¦¬ë·° ì‹¤í–‰
# Trueì¸ checklist í•­ëª©ì— ëŒ€í•œ ì½”ë“œë¦¬ë·° ì‹¤í–‰ (ì „ì œ: Javaì—ì„œ trueì¸ í•­ëª©ì˜ íŒŒì¼ë§Œ ì „ë‹¬ë¨)
async def run_feature_code_review(request: CodeReviewItemRequest) -> Dict:
    feature_id         = request.featureId
    feature_name       = request.featureName
    implements_feature = request.implementsFeature
    checklist_eval     = request.checklistEvaluation
    checklist_file_map = request.checklistFileMap   # âœ… ìƒˆë¡œ ì¶”ê°€ë¨
    full_files         = request.fullFiles

    checklist_reviews = []

    for checklist_item, passed in checklist_eval.items():
        if not passed:
            continue

        # checklistItemì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ ëª©ë¡ ì¶”ì¶œ
        file_paths = checklist_file_map.get(checklist_item, [])
        related_files = [f for f in full_files if f.filePath in file_paths]
        if not related_files:
            continue

        # íŒŒì¼ ë‚´ìš© í•©ì¹˜ê¸°
        merged_code = "\n".join([f"# {f.filePath}\n{f.content}" for f in related_files])

        review = await review_code_with_gpt(
            feature_name=feature_name,
            checklist_item=checklist_item,
            merged_code=merged_code
        )

        print(review)

        checklist_reviews.append({
            "checklistItem": review["checklist_item"],
            "summary":       review["summary"],
            "codeReviews":   review["code_reviews"]
        })

    return {
        "featureId":       feature_id,
        "featureName":     feature_name,
        "codeReviewItems": checklist_reviews,
        "implementation": request.implementsFeature
    }



# async def run_feature_code_review(request: CodeReviewItemRequest) -> Dict:
#     # 1) CamelCaseë¡œ key ì¡°íšŒ
#     checklist_eval   = request.checklistEvaluation,
#     implements_feature = request.implementsFeature,
#     full_files       = request.fullFiles,             # ì´ì œ ë°˜ë“œì‹œ ë“¤ì–´ì™€ì•¼ í•¨
#     feature_name     = request.featureName,
#     feature_id       = request.featureId

#     # 2) ì‹¤ì œ ë¦¬ë·° ëŒ€ìƒ ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ë¦¬ìŠ¤íŠ¸
#     targets = [item for item, passed in checklist_eval.items() if passed] + extra

#     checklist_reviews = []
#     for item in targets:
#         paths = file_map.get(item, [])
#         files = [f for f in full_files if f.filePath in paths]
#         if not files:
#             continue

#         merged_code = "\n".join([f"# {f.filePath}\n{f.content}" for f in files])
#         review = await review_code_with_gpt(
#             feature_name=feature_name,
#             checklist_item=item,
#             merged_code=merged_code
#         )

#         # ë¦¬ë·° ê²°ê³¼ë„ CamelCaseë¡œ ë§¤í•‘
#         checklist_reviews.append({
#             "checklistItem": review["checklist_item"],
#             "summary":       review["summary"],
#             "codeReviews":   review["code_reviews"]
#         })

#     # 3) FeatureReviewResult ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë°˜í™˜
#     return {
#         "featureId":       feature_id,
#         "featureName":     feature_name,
#         "codeReviewItems": checklist_reviews
#     }


# ì½”ë“œë¦¬ë·° GPT í˜¸ì¶œ ë° JSON ì‘ë‹µ íŒŒì‹±
async def review_code_with_gpt(feature_name: str, checklist_item: str, merged_code: str) -> Dict:
    prompt = code_review_prompt.format_messages(
        feature_name=feature_name,
        item=checklist_item,
        merged_code=merged_code
    )

    response = await llm.ainvoke(prompt)
    print(response.content)

    try:
        parsed = json.loads(response.content)

        code_reviews = []
        for r in parsed.get("code_reviews", []):
            code_reviews.append({
                "category":  r.get("category", "ê¸°íƒ€"),
                "filePath":  r.get("filePath", "Unknown.java"),
                "lineRange": r.get("lineRange", "0-0"),
                "severity":  r.get("severity", "LOW"),
                "message":   r.get("message", "(ë‚´ìš© ì—†ìŒ)")
            })

        return {
            "checklist_item": checklist_item,
            "summary": parsed.get("summary", ""),
            "code_reviews": code_reviews
        }

    except json.JSONDecodeError as e:
        return {
            "checklist_item": checklist_item,
            "summary": f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
            "code_reviews": []
        }


# ì½”ë“œ ë¦¬ë·° ìš”ì•½
async def run_feature_review_summary(request: FeatureReviewSummaryRequest) -> dict:

    prompt = review_summary_prompt.format_messages(
        categorized_reviews=request.categorizedReviews
    )

    response = await llm.ainvoke(prompt)
    lines = response.content.strip().split("\n")

    print(response.content)

    def extract(prefix: str) -> str:
        for line in lines:
            if line.startswith(prefix):
                return line.replace(prefix, "").strip()
        return ""
    
    def extract_float(prefix: str) -> float:
        for line in lines:
            if prefix in line:
                try:
                    return float(line.split(prefix)[-1].strip())
                except ValueError:
                    return 0.0
        return 0.0


    def extract(prefix: str) -> str:
        for line in lines:
            if prefix in line:
                return line.split(prefix, 1)[-1].strip()
        return ""


    return {
        "summary_result": {
            "featureId": request.featureId,
            "featureName": request.featureName,
            "overallScore": extract_float("- ì ìˆ˜: "),
            "summary": extract("- ìš”ì•½: "),
            "convention": extract("- ì½”ë”© ì»¨ë²¤ì…˜: "),
            "refactorSuggestion": extract("- ë¦¬íŒ©í† ë§ ì œì•ˆ: "),
            "complexity": extract("- ë³µì¡ë„: "),
            "performance": extract("- ì„±ëŠ¥ ìµœì í™”: "),
            "bugRisk": extract("- ë²„ê·¸ ê°€ëŠ¥ì„±: "),
            "securityRisk": extract("- ë³´ì•ˆ ìœ„í—˜: ")
        }
    }



# ìœ ì¶”í•œ ê¸°ëŠ¥ëª… java ë¡œ ì „ë‹¬
async def send_feature_inference_result_to_java(feature_name: str, commit_hash: str, commit_id: int):
    payload = {
        "featureName": feature_name,
        "commitHash": commit_hash,
        "commitId": commit_id
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(f"{JAVA_API_URL}/feature-inference/result", json=payload)

    if response.status_code == 200:
        print("âœ… ê¸°ëŠ¥ëª… ìœ ì¶” ê²°ê³¼ ì „ì†¡ ì„±ê³µ")
    else:
        print("âŒ ê¸°ëŠ¥ëª… ì „ì†¡ ì‹¤íŒ¨:", response.status_code, response.text)
        

# ì²´í¬ë¦¬ìŠ¤íŠ¸ êµ¬í˜„ í™•ì¸ ì—¬ë¶€ ë° ì¶”ê°€ êµ¬í˜„ í•­ëª© ì „ë‹¬
async def send_checklist_evaluation_result_to_java(state: Dict):
    payload = {
        "featureId": state.get("feature_id"),
        "featureName": state["feature_name"],
        "checklistEvaluation": state["checklist_evaluation"],
        "extraImplemented": state["extra_implemented"]
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(f"{JAVA_API_URL}/checklist-evaluation/result", json=payload)

    if response.status_code == 200:
        print("âœ… checklist í‰ê°€ ê²°ê³¼ ì „ì†¡ ì„±ê³µ")
    else:
        print("âŒ checklist í‰ê°€ ì „ì†¡ ì‹¤íŒ¨:", response.status_code, response.text)

    return state


# ì½”ë“œ ë¦¬ë·° ê²°ê³¼ë¥¼ Javaì— ì „ë‹¬
async def send_code_review_items_to_java(state: Dict):
    review_data = state["code_reviews"]  # âœ… ê¸°ëŠ¥ ë‹¨ìœ„ë¡œ ê°ì‹¼ ë¦¬ë·° ê²°ê³¼

    payload = {
        "featureId": review_data["feature_id"],
        "featureName": review_data["feature_name"],
        "checklistReviews": review_data["checklist_reviews"]  # âœ… key ì´ë¦„ ë³€ê²½!
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(f"{JAVA_API_URL}/code-review/items", json=payload)

    if response.status_code == 200:
        print("âœ… ì½”ë“œë¦¬ë·° í•­ëª© ì „ì†¡ ì„±ê³µ")
    else:
        print("âŒ ì½”ë“œë¦¬ë·° í•­ëª© ì „ì†¡ ì‹¤íŒ¨:", response.status_code, response.text)

    return state



# ì½”ë“œ ë¦¬ë·° ìš”ì•½ java ì „ë‹¬
async def send_code_review_summary_to_java(state: Dict):
    payload = {
        "featureId": state.get("feature_id"),
        "featureName": state["feature_name"],
        "overallReviewSummary": state.get("overall_review_summary")
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(f"{JAVA_API_URL}/code-review/summary", json=payload)

    if response.status_code == 200:
        print("âœ… ì „ì²´ ë¦¬ë·° ìš”ì•½ ì „ì†¡ ì„±ê³µ")
    else:
        print("âŒ ì „ì²´ ìš”ì•½ ì „ì†¡ ì‹¤íŒ¨:", response.status_code, response.text)

    return state


# ê·¸ë˜í”„ ì—°ê²°
builder = StateGraph(CodeReviewState)

# ë…¸ë“œ ìƒì„±
builder.add_node("run_feature_inference", run_feature_inference)
builder.add_node("send_feature_inference_result_to_java", send_feature_inference_result_to_java)
builder.add_node("run_feature_implementation_check", run_feature_implementation_check)
builder.add_node("send_checklist_evaluation_result_to_java", send_checklist_evaluation_result_to_java)
builder.add_node("run_feature_code_review", run_feature_code_review)
builder.add_node("send_code_review_items_to_java", send_code_review_items_to_java)
builder.add_node("run_feature_review_summary", run_feature_review_summary)
builder.add_node("send_code_review_summary_to_java", send_code_review_summary_to_java)


# ë…¸ë“œ ì—°ê²°
builder.set_entry_point("run_feature_inference")

builder.add_edge("run_feature_inference", "send_feature_inference_result_to_java")
builder.add_edge("send_feature_inference_result_to_java", "run_feature_implementation_check")

builder.add_edge("run_feature_implementation_check", "send_checklist_evaluation_result_to_java")
builder.add_edge("send_checklist_evaluation_result_to_java", "run_feature_code_review")
builder.add_edge("run_feature_code_review", "send_code_review_items_to_java")
builder.add_edge("send_code_review_items_to_java", "run_feature_review_summary")


# ì¡°ê±´ ë¶„ê¸°
def should_summarize(state: Dict) -> str:
    return run_feature_review_summary if state.get("implements") else END


builder.add_conditional_edges(
    "send_code_review_items_to_java",
    should_summarize,  # ì¡°ê±´ í•¨ìˆ˜ (True/False ë°˜í™˜)
    {
        True: "run_feature_review_summary",  # ì¡°ê±´ ê²°ê³¼ì— ë”°ë¥¸ ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ (ë¬¸ìì—´)
        False: END
    }
)


builder.add_edge("run_feature_review_summary", "send_code_review_summary_to_java")
builder.add_edge("send_code_review_summary_to_java", END)

graph = builder.compile()

